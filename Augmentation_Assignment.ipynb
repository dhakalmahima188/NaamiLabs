{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5157e426",
   "metadata": {},
   "source": [
    "### Image Augmentation Lab: Cut Out and Mix Up Techniques\n",
    "__Content creator:__ [Pranav Poudel](https://www.linkedin.com/in/pranavpoudel/)\n",
    "\n",
    "----\n",
    "### Objective\n",
    "\n",
    "The objective of this lab is to empower students to implement Mixup and Cutoff data augmentation techniques and analyze their effects through visualization. By engaging in this hands-on experience, students will develop the skills to effectively apply these techniques to their datasets, observe the transformations induced by Mixup and Cutoff, and understand how these augmentations contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6a2ac",
   "metadata": {},
   "source": [
    "### Import important modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from models import get_resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5368e",
   "metadata": {},
   "source": [
    "### Function for Fixing Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7058e",
   "metadata": {},
   "source": [
    "### Model:- ResNet18\n",
    "ResNet is a deep convolutional neural network architecture that uses residual connections to address the problem of vanishing gradients. By enabling the direct flow of gradients through the network, ResNet allows for training very deep networks and has achieved state-of-the-art performance in computer vision tasks. Its residual blocks and skip connections have had a significant impact on advancing the performance of convolutional neural networks.\n",
    "See the [original paper](https://arxiv.org/abs/1512.03385) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6e9c0",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
    "        # It is 1 for ResNet18 and ResNet34.\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, \n",
    "            out_channels*self.expansion, \n",
    "            kernel_size=3, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return  out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock],\n",
    "        num_classes: int  = 1000\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers == 18:\n",
    "            # The following `layers` list defines the number of `BasicBlock` \n",
    "            # to use to build the network and how many basic blocks to stack\n",
    "            # together.\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
    "        # three layers. Here, kernel size is 7.\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7, \n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "    def _make_layer(\n",
    "        self, \n",
    "        block: Type[BasicBlock],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            \"\"\"\n",
    "            This should pass from `layer2` to `layer4` or \n",
    "            when building ResNets50 and above. Section 3.3 of the paper\n",
    "            Deep Residual Learning for Image Recognition\n",
    "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
    "            \"\"\"\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels, \n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False \n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # The spatial dimension of the final layer's feature \n",
    "        # map should be (7, 7) for all ResNets.\n",
    "        feat = self.avgpool(x)\n",
    "        x = torch.flatten(feat, 1)\n",
    "        x = self.fc(x)\n",
    "        return x, feat\n",
    "\n",
    "\n",
    "def get_resnet18(in_channels, num_classes):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_channels:- channel of input image. 3 for RGB\n",
    "        num_classes:- Number of classes to classify. \n",
    "    \"\"\"\n",
    "    return ResNet(img_channels=in_channels, num_layers=18, block=BasicBlock, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefba01",
   "metadata": {},
   "source": [
    "### Hyper-parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "start_epoch = 0  \n",
    "batch_size = 32\n",
    "end_epoch = 10\n",
    "base_learning_rate = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "### Below are hyper-parameters related to augmentation technique\n",
    "n_holes = 1\n",
    "length = 4\n",
    "cutout = False\n",
    "mixup = True\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ca5ff",
   "metadata": {},
   "source": [
    "<h3>Task 1: Implement Cutout Augmentation</h3>\n",
    "\n",
    "In given object code below, implement the Cutout Augmentation in __call__ function. See the [original paper](https://arxiv.org/pdf/1708.04552.pdf) for more details.\n",
    "\n",
    "##### Algorithm: Cutout Augmentation\n",
    "\n",
    "Inputs:\n",
    "- img: Input image tensor\n",
    "- n_holes: Number of cutout holes to apply\n",
    "- length: Length of each cutout hole\n",
    "\n",
    "Output:\n",
    "- Augmented image tensor\n",
    "\n",
    "Procedure:\n",
    "1. Get the height (h) and width (w) of the input image tensor.\n",
    "2. Create a mask tensor of size (h, w) filled with ones of data type float32.\n",
    "3. Repeat the following steps for each cutout hole (n) from 1 to n_holes:\n",
    "   \n",
    "   a. Generate random coordinates (y, x) within the image dimensions (h, w).\n",
    "   \n",
    "   b. Calculate the boundaries of the cutout hole based on the length:\n",
    "      - y1 = max(y - length // 2, 0)\n",
    "      - y2 = min(y + length // 2, h)\n",
    "      - x1 = max(x - length // 2, 0)\n",
    "      - x2 = min(x + length // 2, w)\n",
    "      \n",
    "   c. Set the corresponding region in the mask tensor to 0, indicating the cutout hole.\n",
    "4. Convert the mask tensor to a PyTorch tensor.\n",
    "5. Expand the mask tensor to match the size of the input image tensor.\n",
    "6. Multiply the input image tensor element-wise with the mask tensor to apply the cutout holes.\n",
    "7. Return the augmented image tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "\n",
    "  def __init__(self, n_holes, length):\n",
    "    self.n_holes = n_holes\n",
    "    self.length = length\n",
    "\n",
    "  def __call__(self, img):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7312e",
   "metadata": {},
   "source": [
    "<h3>Task 2: Implement Mixup Augmentation</h3>\n",
    "\n",
    "Implement Mixup Augmenation in mixup_data function below. See the [original paper](https://arxiv.org/pdf/1710.09412.pdf) for more details.\n",
    "\n",
    "\n",
    "##### Algorithm: Mixup Data\n",
    "\n",
    "Inputs:\n",
    "- x: Input data tensor\n",
    "- y: Target labels tensor\n",
    "- alpha: Alpha parameter for mixup (default: 1.0)\n",
    "\n",
    "Outputs:\n",
    "- mixed_x: Mixed input data tensor\n",
    "- y_a: First set of target labels tensor\n",
    "- y_b: Second set of target labels tensor\n",
    "- lam: Lambda value for mixing\n",
    "\n",
    "Procedure:\n",
    "1. If alpha > 0, generate a random lambda value (lam) by sampling from a Beta distribution with alpha as both shape parameters. Otherwise, set lam = 1.\n",
    "\n",
    "2. Get the batch size from the input data tensor x.\n",
    "\n",
    "3. Generate a random permutation of indices using torch.randperm(batch_size).\n",
    "\n",
    "4. Calculate the mixed input data (mixed_x) by linearly combining the input data x and its permuted counterpart, \n",
    "according to the lambda value:\n",
    "\n",
    "   mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "\n",
    "5. Set y_a to be the original target labels tensor y.\n",
    "\n",
    "6. Set y_b to be the permuted target labels tensor y[index].\n",
    "\n",
    "7. Return mixed_x, y_a, y_b, and lam as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34705585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "  '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda\n",
    "  '''\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2601a",
   "metadata": {},
   "source": [
    "### Mixup Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_criterion(y_a, y_b, lam):\n",
    "  '''\n",
    "    - Mixup criterion\n",
    "  '''\n",
    "  return lambda criterion, pred: lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446fcdb",
   "metadata": {},
   "source": [
    "### Datasets and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision transforms\n",
    "if cutout:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        Cutout(n_holes=n_holes, length=length),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        \n",
    "    ])\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        \n",
    "    ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    root='./FashionMNIST', train=True, download=True,\n",
    "    transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    root='./FashionMNIST', train=False, download=True,\n",
    "    transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc44476",
   "metadata": {},
   "source": [
    "### Training and Testing Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
    "        for img, label in tepoch:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            output, _ = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(Loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6225004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_mixup(model, dataloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
    "        for img, label in tepoch:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            inputs, target_a, target_b, lam = mixup_data(img, label)\n",
    "\n",
    "            output, _ = model(inputs)\n",
    "            loss_fn = mixup_criterion(target_a, target_b, lam)\n",
    "            loss = loss_fn(criterion, output)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(Loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    print(\"Testing\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "            tepoch.set_description(\"Testing: \")\n",
    "            for images, labels in tepoch:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs, _ = model(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "num_workers = 0\n",
    "\n",
    "print(f'----> number of workers: {num_workers}')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e4531",
   "metadata": {},
   "source": [
    "### Function for plotting Augmentation Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece46c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mixed_images(images):\n",
    "  inv_normalize = transforms.Normalize(\n",
    "                      mean= [-m/s for m, s in zip((0.5,), (0.5,))],\n",
    "                      std= [1/s for s in (0.5,)]\n",
    "                      )\n",
    "  inv_PIL = transforms.ToPILImage()\n",
    "  fig = plt.figure(figsize=(10, 8))\n",
    "  for i in range(1, len(images) + 1):\n",
    "    image = images[i-1]\n",
    "    ax = fig.add_subplot(1, 4, i)\n",
    "    inv_tensor = inv_normalize(image).cpu()\n",
    "    ax.imshow(inv_PIL(inv_tensor), cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748aa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_information(aug_type, test_acc_list, best_acc):\n",
    "    save_dict = {\n",
    "        \"AugType\":aug_type,\n",
    "        \"accs\":test_acc_list,\n",
    "        \"best_acc\":best_acc\n",
    "    }\n",
    "    with open(f\"training_information{aug_type}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(save_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_Y =  next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a55ba",
   "metadata": {},
   "source": [
    "### Plotting Mixup and/or Cutout Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e183b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixup:\n",
    "  alpha = 0.9\n",
    "  mixed_x, y_a, y_b, lam = mixup_data(batch_X, batch_Y,\n",
    "                                      alpha=alpha)\n",
    "  plot_mixed_images(mixed_x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cutout:\n",
    "    plot_mixed_images(batch_X[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1768bfc",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model and Optimizer Setup\n",
    "aug_type = \"MixUp\" # [Choice:- \"NoAug\", \"CutOut\", \"MixUp\"]\n",
    "\n",
    "net = get_resnet18(in_channels=1, num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=base_learning_rate, betas=(b1, b2))\n",
    "test_acc_list = []\n",
    "best_acc = 0\n",
    "net = net.to(device)\n",
    "for i in range(start_epoch, end_epoch):\n",
    "    if aug_type == \"MixUp\":\n",
    "        train_one_epoch_mixup(net, trainloader, criterion, optimizer, i)    \n",
    "    else: \n",
    "        train_one_epoch(net, trainloader, criterion, optimizer, i)    \n",
    "    acc = test(net, testloader)\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "    test_acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370e290",
   "metadata": {},
   "source": [
    "### Saving Traning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b59d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_information(aug_type, test_acc_list, best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcf7a8",
   "metadata": {},
   "source": [
    "### Task 3: Training on different Augmentation\n",
    "\n",
    "Train on 3 different augmentation mode and visualize the results from below.You can change the hyper-parameters such as alpha, n_holes, etc to see the effect of augmentation techinque. Value of Flags to set for different Augmentation Technque\n",
    "\n",
    "\n",
    "| **cutout** | **mixup** | **aug_type** |\n",
    "|------------|-----------|-------------|\n",
    "| True       | False     | CutOut      |\n",
    "| False      | True      | MixUp       |\n",
    "| False      | False     | NoAug       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c955a89",
   "metadata": {},
   "source": [
    "### Danger Zone\n",
    "Don't run the given code unless you have trained on 3 augmentation techinques\n",
    "Below code is for visualization of test accuracy of different augmentation techniques at different epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a163f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs_type = [\"CutOut\",\"MixUp\",\"NoAug\"]\n",
    "fig, ax = plt.subplots()\n",
    "for type in augs_type:\n",
    "    with open(f\"training_information{type}.pkl\", \"rb\") as f:\n",
    "        train_dict = pickle.load(f)\n",
    "    ax.plot(list(range(start_epoch, end_epoch)), train_dict[\"accs\"], label=type)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Test Accuracy\")\n",
    "ax.set_title(\"Accuracy of Different Augmentation type\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbb760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
