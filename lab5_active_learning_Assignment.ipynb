{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8dced28e",
      "metadata": {
        "id": "8dced28e"
      },
      "source": [
        "### Active Learning Lab: Margin of Confidence Method\n",
        "__Content creator:__ [Pranav Poudel](https://www.linkedin.com/in/pranavpoudel/)\n",
        "\n",
        "----\n",
        "### Objective\n",
        "\n",
        "The objective of the active learning lab is to enable students to implement the active learning method, specifically focusing on the margin of confidence technique. Through hands-on exercises and practical applications, students will learn to apply the margin of confidence method effectively"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603fa6b7",
      "metadata": {
        "id": "603fa6b7"
      },
      "source": [
        "### Import important modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c33fe84",
      "metadata": {
        "id": "4c33fe84"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# from models import get_resnet18"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3f25ae",
      "metadata": {
        "id": "7c3f25ae"
      },
      "source": [
        "### Function for Fixing Seeds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "802d044c",
      "metadata": {
        "id": "802d044c"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "46ae88f7",
      "metadata": {
        "id": "46ae88f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddab390-ba8d-4d7f-a43d-e3ca1cf72f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2023 has been set.\n"
          ]
        }
      ],
      "source": [
        "set_seed(2023)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3400f65",
      "metadata": {
        "id": "b3400f65"
      },
      "source": [
        "### Model:- ResNet18\n",
        "ResNet is a deep convolutional neural network architecture that uses residual connections to address the problem of vanishing gradients. By enabling the direct flow of gradients through the network, ResNet allows for training very deep networks and has achieved state-of-the-art performance in computer vision tasks. Its residual blocks and skip connections have had a significant impact on advancing the performance of convolutional neural networks.\n",
        "See the [original paper](https://arxiv.org/abs/1512.03385) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dcbbb2fe",
      "metadata": {
        "id": "dcbbb2fe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from typing import Type\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        stride: int = 1,\n",
        "        expansion: int = 1,\n",
        "        downsample: nn.Module = None\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
        "        # It is 1 for ResNet18 and ResNet34.\n",
        "        self.expansion = expansion\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, \n",
        "            out_channels, \n",
        "            kernel_size=3, \n",
        "            stride=stride, \n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels, \n",
        "            out_channels*self.expansion, \n",
        "            kernel_size=3, \n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return  out\n",
        "    \n",
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        img_channels: int,\n",
        "        num_layers: int,\n",
        "        block: Type[BasicBlock],\n",
        "        num_classes: int  = 1000\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if num_layers == 18:\n",
        "            # The following `layers` list defines the number of `BasicBlock` \n",
        "            # to use to build the network and how many basic blocks to stack\n",
        "            # together.\n",
        "            layers = [2, 2, 2, 2]\n",
        "            self.expansion = 1\n",
        "        \n",
        "        self.in_channels = 64\n",
        "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
        "        # three layers. Here, kernel size is 7.\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=img_channels,\n",
        "            out_channels=self.in_channels,\n",
        "            kernel_size=7, \n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
        "    def _make_layer(\n",
        "        self, \n",
        "        block: Type[BasicBlock],\n",
        "        out_channels: int,\n",
        "        blocks: int,\n",
        "        stride: int = 1\n",
        "    ) -> nn.Sequential:\n",
        "        downsample = None\n",
        "        if stride != 1:\n",
        "            \"\"\"\n",
        "            This should pass from `layer2` to `layer4` or \n",
        "            when building ResNets50 and above. Section 3.3 of the paper\n",
        "            Deep Residual Learning for Image Recognition\n",
        "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
        "            \"\"\"\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels, \n",
        "                    out_channels*self.expansion,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False \n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
        "            )\n",
        "        )\n",
        "        self.in_channels = out_channels * self.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(\n",
        "                self.in_channels,\n",
        "                out_channels,\n",
        "                expansion=self.expansion\n",
        "            ))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # The spatial dimension of the final layer's feature \n",
        "        # map should be (7, 7) for all ResNets.\n",
        "        feat = self.avgpool(x)\n",
        "        x = torch.flatten(feat, 1)\n",
        "        x = self.fc(x)\n",
        "        return x, feat\n",
        "\n",
        "\n",
        "def get_resnet18(in_channels, num_classes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels:- channel of input image. 3 for RGB\n",
        "        num_classes:- Number of classes to classify. \n",
        "    \"\"\"\n",
        "    return ResNet(img_channels=in_channels, num_layers=18, block=BasicBlock, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e10c96",
      "metadata": {
        "id": "52e10c96"
      },
      "source": [
        "### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8dc75e58",
      "metadata": {
        "id": "8dc75e58"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "start_epoch = 0  \n",
        "batch_size = 32\n",
        "end_epoch = 5 \n",
        "base_learning_rate = 0.0002\n",
        "b1 = 0.5\n",
        "b2 = 0.999"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71ae347",
      "metadata": {
        "id": "f71ae347"
      },
      "source": [
        "### Datasets and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f81fd4f4",
      "metadata": {
        "id": "f81fd4f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096f1116-7eea-4bea-d16d-d6e6f5165225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR10 normalizing\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# torchvision transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./CIFAR10', train=True, download=True,\n",
        "    transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./CIFAR10', train=False, download=True,\n",
        "    transform=transform_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec68419",
      "metadata": {
        "id": "cec68419"
      },
      "source": [
        "### Training and Testing Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52d9b499",
      "metadata": {
        "id": "52d9b499"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
        "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
        "        for img, label in tepoch:\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            output, _ = model(img)\n",
        "            loss = criterion(output, label)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tepoch.set_postfix(Loss=loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf48314f",
      "metadata": {
        "id": "bf48314f"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader):\n",
        "    print(\"Testing\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
        "            tepoch.set_description(\"Testing: \")\n",
        "            for images, labels in tepoch:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                # calculate outputs by running images through the network\n",
        "                outputs, _ = model(images)\n",
        "                # the class with the highest energy is what we choose as prediction\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
        "    return correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d88dc91a",
      "metadata": {
        "id": "d88dc91a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822a6fc9-c125-4b73-c13b-475e25998fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----> number of workers: 4\n"
          ]
        }
      ],
      "source": [
        "# Dataloader\n",
        "num_workers = 4\n",
        "\n",
        "print(f'----> number of workers: {num_workers}')\n",
        "\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "#     trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "# testloader = torch.utils.data.DataLoader(\n",
        "#     testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4629fdc2",
      "metadata": {
        "id": "4629fdc2"
      },
      "source": [
        "### Active Learning Framework\n",
        "\n",
        "1. Initialize data pool with labeled and unlabeled subsets.\n",
        "2. Train a model on the labeled subset.\n",
        "3. Iterate:\n",
        "    - Use the model to predict on the unlabeled data.\n",
        "    - Calculate uncertainty for each unlabeled sample.\n",
        "    - Select the most uncertain samples.\n",
        "    - Label selected samples.\n",
        "    - Add labeled samples to the labeled subset.\n",
        "    - Retrain the model.\n",
        "4. Evaluate model performance.\n",
        "5. Repeat steps 3-4 until a stopping criterion is met or budget is exhausted.\n",
        "6. Train a final model using all labeled data.\n",
        "7. Deploy the final model for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "816aa59d",
      "metadata": {
        "id": "816aa59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5240da-f71f-41ee-d22c-32c63d8d9ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "#Active Learning Framework\n",
        "train_indices = np.arange(len(trainset))\n",
        "INITIAL_BUDGET = 10000  #cost : for example doctor in radiology\n",
        "BUDGET = 5000\n",
        "num_cycle = 3\n",
        "\n",
        "initial_indices = random.sample(list(train_indices), INITIAL_BUDGET)\n",
        "train_sampler = data.sampler.SubsetRandomSampler(initial_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sampler, \n",
        "        batch_size=batch_size, num_workers=num_workers)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "initial_unlabeled_indices = np.setdiff1d(list(train_indices), initial_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "34135d2f",
      "metadata": {
        "id": "34135d2f"
      },
      "outputs": [],
      "source": [
        "#Model and Optimizer Setup\n",
        "net = get_resnet18(in_channels=3, num_classes=10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=base_learning_rate, betas=(b1, b2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea0bd1c",
      "metadata": {
        "id": "5ea0bd1c"
      },
      "outputs": [],
      "source": [
        "net = net.to(device)\n",
        "for i in range(start_epoch, end_epoch):\n",
        "    train_one_epoch(net, trainloader, criterion, optimizer, i)    \n",
        "    acc = test(net, testloader)\n",
        "    torch.save(net.state_dict(), \"initial_checkpoint.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bcb618",
      "metadata": {
        "id": "51bcb618"
      },
      "outputs": [],
      "source": [
        "#Random Sampling\n",
        "import random\n",
        "def random_sampler(unlabeled_indices):\n",
        "    random.shuffle(unlabeled_indices)\n",
        "    arg = np.random.randint(len(unlabeled_indices), size=len(unlabeled_indices))\n",
        "    indices_to_label = unlabeled_indices[arg][:BUDGET]\n",
        "    return indices_to_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a686ca0a",
      "metadata": {
        "id": "a686ca0a"
      },
      "source": [
        "<h3>Task 1: Implement Margin of Confidence Method</h3>\n",
        "\n",
        "Implement Margin of Confidence Method using following guideline in given loop below.\n",
        "\n",
        "1. Calculate Probabilities\n",
        "2. Get top two Probabilities\n",
        "3. Calculate difference between top two probabilities\n",
        "4. Calculate uncertainity = 1 - difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1a6daf",
      "metadata": {
        "id": "3f1a6daf"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def calculate_bvsb_uncertainty(model, data_loader, budget):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        unc_preds = []\n",
        "        for images, _ in data_loader:\n",
        "            outputs, _ = model(images.to(device))\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            top2_probs, _ = torch.topk(probabilities, k=2, dim=1)\n",
        "            differences = top2_probs[:, 0] - top2_probs[:, 1]\n",
        "            uncertainity = 1 - differences\n",
        "            unc_preds.extend(uncertainity.cpu())\n",
        "        unc_preds = torch.stack(unc_preds)\n",
        "    scores, query_indices = torch.topk(unc_preds, budget)\n",
        "    return query_indices, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0dff38",
      "metadata": {
        "id": "ea0dff38"
      },
      "outputs": [],
      "source": [
        "def bvsb_sampler(trainset, models, unlabeled_indices):\n",
        "    unlabeled_dataloader = torch.utils.data.DataLoader(trainset, sampler=torch.utils.data.SequentialSampler(unlabeled_indices), batch_size=batch_size)\n",
        "    arg, _ =  calculate_bvsb_uncertainty(models, unlabeled_dataloader, BUDGET)\n",
        "    indices_to_label = list(torch.tensor(unlabeled_indices)[arg].numpy())\n",
        "    return indices_to_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8f33597",
      "metadata": {
        "id": "b8f33597"
      },
      "source": [
        "### Random Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe3153f",
      "metadata": {
        "id": "4fe3153f"
      },
      "outputs": [],
      "source": [
        "indices_to_label = random_sampler(initial_unlabeled_indices)\n",
        "current_indices = list(initial_indices) + list(indices_to_label)\n",
        "sampler = data.sampler.SubsetRandomSampler(current_indices)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=sampler, \n",
        "        batch_size=batch_size, num_workers=num_workers)\n",
        "unlabeled_indices = np.setdiff1d(list(train_indices), current_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9145cb63",
      "metadata": {
        "id": "9145cb63"
      },
      "outputs": [],
      "source": [
        "random_acc = []\n",
        "for cycle in range(1,num_cycle):\n",
        "    net = get_resnet18(in_channels=3, num_classes=10)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=base_learning_rate, betas=(b1, b2))\n",
        "    net = net.to(device)\n",
        "    best_acc = 0\n",
        "    print(f\"Cycle: {cycle}\")\n",
        "    for i in range(start_epoch, end_epoch):\n",
        "        train_one_epoch(net, trainloader, criterion, optimizer, i)    \n",
        "        acc = test(net, testloader)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "    random_acc.append(best_acc)\n",
        "    \n",
        "    indices_to_label = random_sampler(unlabeled_indices)\n",
        "\n",
        "    current_indices = list(current_indices) + list(indices_to_label)\n",
        "    sampler = data.sampler.SubsetRandomSampler(current_indices)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, sampler=sampler, \n",
        "        batch_size=batch_size, num_workers=num_workers)\n",
        "    unlabeled_indices = np.setdiff1d(list(train_indices), current_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc9d7fcf",
      "metadata": {
        "id": "dc9d7fcf"
      },
      "source": [
        "### Uncertainity Based Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4591932a",
      "metadata": {
        "id": "4591932a"
      },
      "outputs": [],
      "source": [
        "#best vs second best sampler\n",
        "net.load_state_dict(torch.load(\"initial_checkpoint.pt\"))\n",
        "indices_to_label = bvsb_sampler(trainset, net, initial_unlabeled_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2592b8c3",
      "metadata": {
        "id": "2592b8c3"
      },
      "outputs": [],
      "source": [
        "current_indices = list(initial_indices) + list(indices_to_label)\n",
        "sampler = data.sampler.SubsetRandomSampler(current_indices)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=sampler, \n",
        "        batch_size=batch_size, num_workers=num_workers)\n",
        "unlabeled_indices = np.setdiff1d(list(train_indices), current_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d46c9a",
      "metadata": {
        "id": "a7d46c9a"
      },
      "outputs": [],
      "source": [
        "bvsb_acc = []\n",
        "for cycle in range(1,num_cycle):\n",
        "    net = get_resnet18(in_channels=3, num_classes=10)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=base_learning_rate, betas=(b1, b2))\n",
        "    net = net.to(device)\n",
        "    best_acc = 0\n",
        "    print(f\"Cycle: {cycle}\")\n",
        "    for i in range(start_epoch, end_epoch):\n",
        "        train_one_epoch(net, trainloader, criterion, optimizer, i)    \n",
        "        acc = test(net, testloader)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(net.state_dict(), f\"bvsb_best{cycle}.pt\")\n",
        "    bvsb_acc.append(best_acc)\n",
        "\n",
        "    net.load_state_dict(torch.load(f\"bvsb_best{cycle}.pt\"))\n",
        "    indices_to_label = bvsb_sampler(trainset, net, unlabeled_indices)\n",
        "\n",
        "    current_indices = list(current_indices) + list(indices_to_label)\n",
        "    sampler = data.sampler.SubsetRandomSampler(current_indices)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, sampler=sampler, \n",
        "        batch_size=batch_size, num_workers=num_workers)\n",
        "    unlabeled_indices = np.setdiff1d(list(train_indices), current_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6683474",
      "metadata": {
        "id": "d6683474"
      },
      "outputs": [],
      "source": [
        "active_learning_method = [\"Random\", \"BvSB\"]\n",
        "accs = [random_acc, bvsb_acc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98334897",
      "metadata": {
        "id": "98334897"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(len(active_learning_method)):\n",
        "    # ax.plot(list(range(start_epoch, end_epoch)), train_dict[\"accs\"], label=type)\n",
        "    method_name = active_learning_method[i]\n",
        "    method_acc = accs[i]\n",
        "    no_trails = list(range(len(method_acc)))\n",
        "    ax.plot(no_trails, method_acc, label=method_name)\n",
        "ax.set_xlabel(\"Number of Cycles\")\n",
        "ax.set_ylabel(\"Test Accuracy\")\n",
        "ax.set_title(\"Accuracy of Different Active Learning Method\")\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109f4f79",
      "metadata": {
        "id": "109f4f79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15fffeaa",
      "metadata": {
        "id": "15fffeaa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}